{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "\n",
    "# المشروع الخامس"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "أهلاً بكم في المشروع الخامس من علم البيانات. في هذا المشروع، سنعمل معاً على التعرف على المؤثرين في الشبكات الاجتماعية باستخدام بيانات من موقع تويتر باستخدام العديد من السمات. ندعوك لقراءة تفاصيل المسابقة في كاقل:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.kaggle.com/c/predict-who-is-more-influential-in-a-social-network/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "ملاحظة: عليك تعديل الخانات التي يوجد فيها الكود أدناه قبل تسليم المشروع. جميع الخانات الأخرى يجب ان تبقى كما هي بدون أي \n",
    "تعديل.\n",
    "\n",
    "```\n",
    "############################\n",
    "# عليك تعديل هذه الخانة قبل تسليم المشروع\n",
    "# YOU HAVE TO EDIT THIS CELLL\n",
    "############################\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "الهدف من هذا المشروع هو توقع المؤثرين في الشبكات الاجتماعية. البيانات الحالية مكونة من 5500 صف و 23 عمود. كل صف يحتوي على معلومات مستخدمين اثنين (11 متغير لكل منهم) بالإضافة إلى متغير الاستجابة والذي يحتوي على المستخدم الأكثر تأثيراً بين الاثنين (1 يعني أن A هو الأكثر تأثيراً بينما 0 يعني أن B هو الأكثر تأثيراً."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "\n",
    "# قراءة البيانات"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Choice', 'A_follower_count', 'A_following_count', 'A_listed_count',\n",
       "       'A_mentions_received', 'A_retweets_received', 'A_mentions_sent',\n",
       "       'A_retweets_sent', 'A_posts', 'A_network_feature_1',\n",
       "       'A_network_feature_2', 'A_network_feature_3', 'B_follower_count',\n",
       "       'B_following_count', 'B_listed_count', 'B_mentions_received',\n",
       "       'B_retweets_received', 'B_mentions_sent', 'B_retweets_sent', 'B_posts',\n",
       "       'B_network_feature_1', 'B_network_feature_2', 'B_network_feature_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data['Choice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(columns='Choice', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "لنرى أولاً توزيع متغير الاستجابة:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequencies of each label in the dataset: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    0.509455\n",
       "0    0.490545\n",
       "Name: Choice, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Frequencies of each label in the dataset: ')\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "يوضح التوزيع أعلاه أن لدينا توازن بين الأصناف بحيث نستطيع المضي قدماً دون الاكتراث لهذا الأمر لاحقاً."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "لنلق الآن نظرة على أنواع المتغيرات لنتأكد أن جميع المتغيرات مقروءة بشكل سليم:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5500 entries, 0 to 5499\n",
      "Data columns (total 22 columns):\n",
      "A_follower_count       5500 non-null int64\n",
      "A_following_count      5500 non-null int64\n",
      "A_listed_count         5500 non-null int64\n",
      "A_mentions_received    5500 non-null float64\n",
      "A_retweets_received    5500 non-null float64\n",
      "A_mentions_sent        5500 non-null float64\n",
      "A_retweets_sent        5500 non-null float64\n",
      "A_posts                5500 non-null float64\n",
      "A_network_feature_1    5500 non-null int64\n",
      "A_network_feature_2    5500 non-null float64\n",
      "A_network_feature_3    5500 non-null float64\n",
      "B_follower_count       5500 non-null int64\n",
      "B_following_count      5500 non-null int64\n",
      "B_listed_count         5500 non-null int64\n",
      "B_mentions_received    5500 non-null float64\n",
      "B_retweets_received    5500 non-null float64\n",
      "B_mentions_sent        5500 non-null float64\n",
      "B_retweets_sent        5500 non-null float64\n",
      "B_posts                5500 non-null float64\n",
      "B_network_feature_1    5500 non-null int64\n",
      "B_network_feature_2    5500 non-null float64\n",
      "B_network_feature_3    5500 non-null float64\n",
      "dtypes: float64(14), int64(8)\n",
      "memory usage: 945.4 KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "لنبدأ باستعراض ملخص للبيانات باستخدام describe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_follower_count</th>\n",
       "      <th>A_following_count</th>\n",
       "      <th>A_listed_count</th>\n",
       "      <th>A_mentions_received</th>\n",
       "      <th>A_retweets_received</th>\n",
       "      <th>A_mentions_sent</th>\n",
       "      <th>A_retweets_sent</th>\n",
       "      <th>A_posts</th>\n",
       "      <th>A_network_feature_1</th>\n",
       "      <th>A_network_feature_2</th>\n",
       "      <th>...</th>\n",
       "      <th>B_following_count</th>\n",
       "      <th>B_listed_count</th>\n",
       "      <th>B_mentions_received</th>\n",
       "      <th>B_retweets_received</th>\n",
       "      <th>B_mentions_sent</th>\n",
       "      <th>B_retweets_sent</th>\n",
       "      <th>B_posts</th>\n",
       "      <th>B_network_feature_1</th>\n",
       "      <th>B_network_feature_2</th>\n",
       "      <th>B_network_feature_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>5500.00</td>\n",
       "      <td>5500.00</td>\n",
       "      <td>5500.00</td>\n",
       "      <td>5500.00</td>\n",
       "      <td>5500.00</td>\n",
       "      <td>5500.00</td>\n",
       "      <td>5500.00</td>\n",
       "      <td>5500.00</td>\n",
       "      <td>5500.00</td>\n",
       "      <td>5500.00</td>\n",
       "      <td>...</td>\n",
       "      <td>5500.00</td>\n",
       "      <td>5500.00</td>\n",
       "      <td>5500.00</td>\n",
       "      <td>5500.00</td>\n",
       "      <td>5500.00</td>\n",
       "      <td>5500.00</td>\n",
       "      <td>5500.00</td>\n",
       "      <td>5500.00</td>\n",
       "      <td>5500.00</td>\n",
       "      <td>5500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>649883.95</td>\n",
       "      <td>12658.95</td>\n",
       "      <td>5952.45</td>\n",
       "      <td>2666.03</td>\n",
       "      <td>1032.37</td>\n",
       "      <td>6.01</td>\n",
       "      <td>1.11</td>\n",
       "      <td>9.09</td>\n",
       "      <td>5267.77</td>\n",
       "      <td>84.81</td>\n",
       "      <td>...</td>\n",
       "      <td>12738.26</td>\n",
       "      <td>5903.15</td>\n",
       "      <td>2554.60</td>\n",
       "      <td>997.15</td>\n",
       "      <td>6.10</td>\n",
       "      <td>1.11</td>\n",
       "      <td>9.51</td>\n",
       "      <td>5254.93</td>\n",
       "      <td>85.02</td>\n",
       "      <td>3745.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2028787.44</td>\n",
       "      <td>49008.67</td>\n",
       "      <td>17339.14</td>\n",
       "      <td>29165.43</td>\n",
       "      <td>10954.95</td>\n",
       "      <td>9.52</td>\n",
       "      <td>1.91</td>\n",
       "      <td>18.31</td>\n",
       "      <td>28946.78</td>\n",
       "      <td>104.07</td>\n",
       "      <td>...</td>\n",
       "      <td>50054.52</td>\n",
       "      <td>16298.46</td>\n",
       "      <td>25088.73</td>\n",
       "      <td>9342.01</td>\n",
       "      <td>9.73</td>\n",
       "      <td>1.94</td>\n",
       "      <td>19.42</td>\n",
       "      <td>26778.82</td>\n",
       "      <td>106.69</td>\n",
       "      <td>5518.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2663.75</td>\n",
       "      <td>322.00</td>\n",
       "      <td>85.00</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.63</td>\n",
       "      <td>12.00</td>\n",
       "      <td>14.99</td>\n",
       "      <td>...</td>\n",
       "      <td>322.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.82</td>\n",
       "      <td>11.00</td>\n",
       "      <td>15.18</td>\n",
       "      <td>1206.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>45589.00</td>\n",
       "      <td>778.00</td>\n",
       "      <td>932.00</td>\n",
       "      <td>48.77</td>\n",
       "      <td>14.03</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>3.56</td>\n",
       "      <td>195.00</td>\n",
       "      <td>54.93</td>\n",
       "      <td>...</td>\n",
       "      <td>773.00</td>\n",
       "      <td>890.00</td>\n",
       "      <td>48.77</td>\n",
       "      <td>14.03</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.34</td>\n",
       "      <td>3.34</td>\n",
       "      <td>190.00</td>\n",
       "      <td>54.93</td>\n",
       "      <td>2206.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>392738.00</td>\n",
       "      <td>2838.00</td>\n",
       "      <td>6734.00</td>\n",
       "      <td>349.82</td>\n",
       "      <td>118.70</td>\n",
       "      <td>7.20</td>\n",
       "      <td>1.32</td>\n",
       "      <td>10.69</td>\n",
       "      <td>1323.00</td>\n",
       "      <td>109.70</td>\n",
       "      <td>...</td>\n",
       "      <td>2838.00</td>\n",
       "      <td>6734.00</td>\n",
       "      <td>374.37</td>\n",
       "      <td>107.08</td>\n",
       "      <td>6.87</td>\n",
       "      <td>1.32</td>\n",
       "      <td>10.60</td>\n",
       "      <td>1323.00</td>\n",
       "      <td>112.19</td>\n",
       "      <td>4349.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>36543194.00</td>\n",
       "      <td>1165830.00</td>\n",
       "      <td>549144.00</td>\n",
       "      <td>1145218.99</td>\n",
       "      <td>435825.87</td>\n",
       "      <td>76.81</td>\n",
       "      <td>16.29</td>\n",
       "      <td>193.07</td>\n",
       "      <td>920838.00</td>\n",
       "      <td>1121.00</td>\n",
       "      <td>...</td>\n",
       "      <td>664324.00</td>\n",
       "      <td>549144.00</td>\n",
       "      <td>1145218.99</td>\n",
       "      <td>435825.87</td>\n",
       "      <td>76.81</td>\n",
       "      <td>16.29</td>\n",
       "      <td>193.07</td>\n",
       "      <td>920838.00</td>\n",
       "      <td>1861.58</td>\n",
       "      <td>75526.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       A_follower_count  A_following_count  A_listed_count  \\\n",
       "count           5500.00            5500.00         5500.00   \n",
       "mean          649883.95           12658.95         5952.45   \n",
       "std          2028787.44           49008.67        17339.14   \n",
       "min               16.00               0.00            0.00   \n",
       "25%             2663.75             322.00           85.00   \n",
       "50%            45589.00             778.00          932.00   \n",
       "75%           392738.00            2838.00         6734.00   \n",
       "max         36543194.00         1165830.00       549144.00   \n",
       "\n",
       "       A_mentions_received  A_retweets_received  A_mentions_sent  \\\n",
       "count              5500.00              5500.00          5500.00   \n",
       "mean               2666.03              1032.37             6.01   \n",
       "std               29165.43             10954.95             9.52   \n",
       "min                   0.10                 0.10             0.10   \n",
       "25%                   3.45                 0.72             0.36   \n",
       "50%                  48.77                14.03             2.30   \n",
       "75%                 349.82               118.70             7.20   \n",
       "max             1145218.99            435825.87            76.81   \n",
       "\n",
       "       A_retweets_sent  A_posts  A_network_feature_1  A_network_feature_2  \\\n",
       "count          5500.00  5500.00              5500.00              5500.00   \n",
       "mean              1.11     9.09              5267.77                84.81   \n",
       "std               1.91    18.31             28946.78               104.07   \n",
       "min               0.10     0.10                 0.00                 0.00   \n",
       "25%               0.10     0.63                12.00                14.99   \n",
       "50%               0.34     3.56               195.00                54.93   \n",
       "75%               1.32    10.69              1323.00               109.70   \n",
       "max              16.29   193.07            920838.00              1121.00   \n",
       "\n",
       "       ...  B_following_count  B_listed_count  B_mentions_received  \\\n",
       "count  ...            5500.00         5500.00              5500.00   \n",
       "mean   ...           12738.26         5903.15              2554.60   \n",
       "std    ...           50054.52        16298.46             25088.73   \n",
       "min    ...               0.00            0.00                 0.10   \n",
       "25%    ...             322.00           75.00                 3.26   \n",
       "50%    ...             773.00          890.00                48.77   \n",
       "75%    ...            2838.00         6734.00               374.37   \n",
       "max    ...          664324.00       549144.00           1145218.99   \n",
       "\n",
       "       B_retweets_received  B_mentions_sent  B_retweets_sent  B_posts  \\\n",
       "count              5500.00          5500.00          5500.00  5500.00   \n",
       "mean                997.15             6.10             1.11     9.51   \n",
       "std                9342.01             9.73             1.94    19.42   \n",
       "min                   0.10             0.10             0.10     0.10   \n",
       "25%                   0.71             0.36             0.10     0.82   \n",
       "50%                  14.03             2.25             0.34     3.34   \n",
       "75%                 107.08             6.87             1.32    10.60   \n",
       "max              435825.87            76.81            16.29   193.07   \n",
       "\n",
       "       B_network_feature_1  B_network_feature_2  B_network_feature_3  \n",
       "count              5500.00              5500.00              5500.00  \n",
       "mean               5254.93                85.02              3745.18  \n",
       "std               26778.82               106.69              5518.40  \n",
       "min                   0.00                 0.00                 0.00  \n",
       "25%                  11.00                15.18              1206.50  \n",
       "50%                 190.00                54.93              2206.42  \n",
       "75%                1323.00               112.19              4349.91  \n",
       "max              920838.00              1861.58             75526.08  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe().round(decimals=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "من خلال تفحص قيم الانحراف المعياري (std)، نجد أن أغلب المتغيرات لديها قيم عالية جداً بما يعكس توزيعاً عريضاً للبيانات، وهذا لا يساعدنا بشكل كبير. سنقوم بتجهيز البيانات وإنشاء بعض المتغيرات الجديدة."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "\n",
    "# تجهيز البيانات"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "الهدف من تجهيز البيانات هو تنظيف البيانات والتحقق منها بالإضافة إلى إضافة أي متغيرات جديدة قد تكون مهمة في عملية التصنيف. سنبدأ أولاً بالتأكد من عدم وجود أي بيانات مفقودة، وملئها بالطريقة المناسبة إن وجدت:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A_follower_count       0\n",
       "A_following_count      0\n",
       "A_listed_count         0\n",
       "A_mentions_received    0\n",
       "A_retweets_received    0\n",
       "A_mentions_sent        0\n",
       "A_retweets_sent        0\n",
       "A_posts                0\n",
       "A_network_feature_1    0\n",
       "A_network_feature_2    0\n",
       "A_network_feature_3    0\n",
       "B_follower_count       0\n",
       "B_following_count      0\n",
       "B_listed_count         0\n",
       "B_mentions_received    0\n",
       "B_retweets_received    0\n",
       "B_mentions_sent        0\n",
       "B_retweets_sent        0\n",
       "B_posts                0\n",
       "B_network_feature_1    0\n",
       "B_network_feature_2    0\n",
       "B_network_feature_3    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#تم التعديل\n",
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "كيف يمكن أن ننشيء أعمدة جديدة؟ سنقوم بإنشاء أعمدة جديدة تعبر عن الفرق في القيم بين المستخدم A والمستخدم B. فمثلا، بالإضافة إلى A_follower_count و B_follower_count، نستطيع إيجاد الفرق بين المتغيرين وإنشاء متغير ثالث يعبر عن الفرق. سأترك المهمة لك:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#تم التعديل\n",
    "\n",
    "def get_substracted_features(df):\n",
    "    train_data['AB_follower_count']   = train_data['A_follower_count'].subtract(train_data['B_follower_count']) \n",
    "    train_data['AB_following_count']  = train_data['A_following_count'].subtract(train_data['B_following_count']) \n",
    "    train_data['AB_listed_count']     = train_data['A_listed_count'].subtract(train_data['B_listed_count']) \n",
    "    train_data['AB_mentions_received']= train_data['A_mentions_received'].subtract(train_data['B_mentions_received']) \n",
    "    train_data['AB_retweets_received']= train_data['A_retweets_received'].subtract(train_data['B_retweets_received']) \n",
    "    train_data['AB_mentions_sent']    = train_data['A_mentions_sent'].subtract(train_data['B_mentions_sent']) \n",
    "    train_data['AB_retweets_sent']    = train_data['A_retweets_sent'].subtract(train_data['B_retweets_sent']) \n",
    "    train_data['AB_posts']            = train_data['A_posts'].subtract(train_data['B_posts']) \n",
    "    train_data['AB_network_feature_1']= train_data['A_network_feature_1'].subtract(train_data['B_network_feature_1']) \n",
    "    train_data['AB_network_feature_2']= train_data['A_network_feature_2'].subtract(train_data['B_network_feature_2']) \n",
    "    train_data['AB_network_feature_3']= train_data['A_network_feature_3'].subtract(train_data['B_network_feature_3'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "إضافة إلى متغيرات الفرق، نستطيع كذلك استخدام متغيرات جديدة عبارة عن متغيرات النسبة. فمثلا، نستطيع حساب نسبة متابعي مستخدم ما إلى من يتابعهم، وذلك مثلاً بقسمة A_follower_count على A_following_count وهكذا. لنقم بكتابة الأمر في الخانة أدناه:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#تم التعديل\n",
    "\n",
    "def get_ratio_features(df):\n",
    "    train_data['r_follower_count_A']= train_data['A_follower_count'] / train_data['A_following_count']\n",
    "    train_data['r_follower_count_B']= train_data['B_follower_count'] / train_data['B_following_count']\n",
    "    train_data['r_mentions_A']      = train_data['A_mentions_received'] / train_data['A_mentions_sent']\n",
    "    train_data['r_mentions_B']      = train_data['A_retweets_received'] / train_data['A_retweets_sent']\n",
    "    train_data['r_RT_A']            = train_data['B_mentions_received'] / train_data['B_mentions_sent']\n",
    "    train_data['r_RT_B']            = train_data['B_retweets_received'] / train_data['B_retweets_sent']\n",
    "    train_data['r_postlist_A']      = train_data['A_posts'] / train_data['A_listed_count']\n",
    "    train_data['r_postlist_B']      = train_data['B_posts'] / train_data['B_listed_count']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "سنقوم الآن بدمج هذه العمليات في أمر واحد ليسهل تطبيقه مرة واحدة على بيانات الاختبار. قمنا كذلك بإضافة المزيد من اللمسات الإضافية والتي سنرى أثرها بعد قليل."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_process_features(df):\n",
    "    X_subst_features = get_substracted_features(np.log(df+1))     \n",
    "    X_ratio_features = get_ratio_features( df+1)    \n",
    "    X_features = pd.concat([np.log(df+1), X_subst_features, X_ratio_features], axis=1)\n",
    "\n",
    "    X_features['r_follower_count_A'] = np.log(X_features['r_follower_count_A'])\n",
    "    X_features['r_follower_count_B'] = np.log(X_features['r_follower_count_B'])\n",
    "    X_features['r_mentions_A'] = np.log(X_features['r_mentions_A'])\n",
    "    X_features['r_mentions_B'] = np.log(X_features['r_mentions_B'])\n",
    "    X_features['r_RT_A'] = np.log(X_features['r_RT_A'])\n",
    "    X_features['r_RT_B'] = np.log(X_features['r_RT_B'])\n",
    "    X_features['r_postlist_A'] = np.log(X_features['r_postlist_A'])\n",
    "    X_features['r_postlist_B'] = np.log(X_features['r_postlist_B'])\n",
    "    \n",
    "    return X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "train_data = get_process_features(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "لنلق الآن نظرة على الأعمدة بعد التجهيز:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A_follower_count', 'A_following_count', 'A_listed_count',\n",
       "       'A_mentions_received', 'A_retweets_received', 'A_mentions_sent',\n",
       "       'A_retweets_sent', 'A_posts', 'A_network_feature_1',\n",
       "       'A_network_feature_2', 'A_network_feature_3', 'B_follower_count',\n",
       "       'B_following_count', 'B_listed_count', 'B_mentions_received',\n",
       "       'B_retweets_received', 'B_mentions_sent', 'B_retweets_sent', 'B_posts',\n",
       "       'B_network_feature_1', 'B_network_feature_2', 'B_network_feature_3',\n",
       "       'AB_follower_count', 'AB_following_count', 'AB_listed_count',\n",
       "       'AB_mentions_received', 'AB_retweets_received', 'AB_mentions_sent',\n",
       "       'AB_retweets_sent', 'AB_posts', 'AB_network_feature_1',\n",
       "       'AB_network_feature_2', 'AB_network_feature_3', 'r_follower_count_A',\n",
       "       'r_follower_count_B', 'r_mentions_A', 'r_mentions_B', 'r_RT_A',\n",
       "       'r_RT_B', 'r_postlist_A', 'r_postlist_B', 'A_follower_count',\n",
       "       'A_following_count', 'A_listed_count', 'A_mentions_received',\n",
       "       'A_retweets_received', 'A_mentions_sent', 'A_retweets_sent', 'A_posts',\n",
       "       'A_network_feature_1', 'A_network_feature_2', 'A_network_feature_3',\n",
       "       'B_follower_count', 'B_following_count', 'B_listed_count',\n",
       "       'B_mentions_received', 'B_retweets_received', 'B_mentions_sent',\n",
       "       'B_retweets_sent', 'B_posts', 'B_network_feature_1',\n",
       "       'B_network_feature_2', 'B_network_feature_3', 'A_follower_count',\n",
       "       'A_following_count', 'A_listed_count', 'A_mentions_received',\n",
       "       'A_retweets_received', 'A_mentions_sent', 'A_retweets_sent', 'A_posts',\n",
       "       'A_network_feature_1', 'A_network_feature_2', 'A_network_feature_3',\n",
       "       'B_follower_count', 'B_following_count', 'B_listed_count',\n",
       "       'B_mentions_received', 'B_retweets_received', 'B_mentions_sent',\n",
       "       'B_retweets_sent', 'B_posts', 'B_network_feature_1',\n",
       "       'B_network_feature_2', 'B_network_feature_3', 'AB_follower_count',\n",
       "       'AB_following_count', 'AB_listed_count', 'AB_mentions_received',\n",
       "       'AB_retweets_received', 'AB_mentions_sent', 'AB_retweets_sent',\n",
       "       'AB_posts', 'AB_network_feature_1', 'AB_network_feature_2',\n",
       "       'AB_network_feature_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "الخطوة الأخيرة في تجهيز البيانات هي في تسوية البيانات. في هذه المرة، لن نقوم بعمل ذلك يدوياً ولكن باستخدام أمر StandardScalar() من مكتبة scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def preprocess_data(df, scaler=None):\n",
    "    '''\n",
    "    In this function, we will standardize data to have a mean of zero and a unit variance. The standardized data\n",
    "    and a scalar object (to be used for testing data) are returned.\n",
    "    '''\n",
    "    if not scaler:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(df.values)\n",
    "    df = pd.DataFrame(scaler.transform(df.values), columns=df.columns)\n",
    "    return df, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-3af22a50a7b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-554f238802c0>\u001b[0m in \u001b[0;36mpreprocess_data\u001b[1;34m(df, scaler)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    661\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[0;32m    662\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[0;32m    664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m         \u001b[1;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 542\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "train_data, scaler = preprocess_data(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "حتى نرى أثر الخطوات التي أجريناها على تجهيز البيانات، سنقم برسم المتغيرات ولكن بتمييز متغير الاستجابة. في الحالة المثالية، نريد أن نرى تمايزاً واضحا في أكبر عدد ممكن من المتغيرات بين الأصناف في متغير الاستجابة."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_names = ['s_following_count', 's_listed_count', 's_mentions_received',\n",
    "       's_retweets_received', 's_mentions_sent', 's_retweets_sent', 's_posts',\n",
    "       's_network_feature_1', 's_network_feature_2', 's_network_feature_3',\n",
    "       'r_follower_count_A', 'r_follower_count_B', 'r_mentions_A',\n",
    "       'r_mentions_B', 'r_RT_A', 'r_RT_B', 'r_postlist_A', 'r_postlist_B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograms(X_features, features_names, Y,  cols = 3, figsize=(8,20), **args):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    total = len(features_names)\n",
    "    rows = total // cols \n",
    "    rows += total % cols\n",
    "    position = range(1,total + 1)\n",
    "    for k in range(total):\n",
    "        ax = fig.add_subplot(rows,cols,position[k])\n",
    "        plt.hist(X_features[features_names[k]].values[Y==0], label='Zero', **args)\n",
    "        plt.hist(X_features[features_names[k]].values[Y==1], label='One', **args)\n",
    "        plt.title(features_names[k])\n",
    "        plt.legend(loc='best')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(train_data, features_names, y.values, cols = 3, figsize=(15,20), alpha=.5, bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "يوضح الشكل أعلاه أن لدينا توزيعين مختلفين للأصناف المختلفة وهذا خبر جيد جداً."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "\n",
    "# نمذجة البيانات"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "سنقوم الآن بنمذجة البيانات باستخدام عدة نماذج ونرى كيف يمكن أن نحسن من أداء النموذج. تحديدا، سنقوم بتدريب النموذج باستخدام البيانات  (training_data) ونرى أداء النموذج باستخدام عدد من المُدخلات. لنبدأ بالانحدار اللوجستي. في الخانة أدناه، قم باستيراد كلاً من مكتبة الانحدار اللوجستي، وأمر cross_val_score ثم استخدمهم في تدريب النموذج والتحقق من صحته."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#تم التعديل\n",
    "from sklearn.model.linear import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model1 = LogisticRegression()\n",
    "scores = cross_val_score(model1, train_data, y, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "الآن سنكرر نفس العملية ولكن باستخدام قيمة أخرى للمُدخل C وهو يعبر عن مقدار الضبط (regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#تم التعديل\n",
    "model2 = LogisticRegression()\n",
    "scores = cross_val_score(model2, train_data, y, cv='regularization', scoring='accuracy')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "هل تلاحظ أي فرق في الدقة ؟"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "على الأغلب لاحظت أن هناك فرقاً طفيفاً في أداء النموذج باستخدام قيمة أخرى للمدخل. في الحقيقة كل قيمة ل C ستعطيك نتيجة مختلفة. فكيف نعرف القيمة الصحيحة التي يجب علينا استخدامها؟ سنقوم بالبحث عن هذه القيمة باستخدام  Grid Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "في الخانة التالية، تجد قيم مختلفة ل C وقيم مختلفة ل fit_intercept. ما عليك الآن هو قراءة الأمر GridSearchCV ومن ثم استخدام القيم من الخانة التالية في البحث عن أفضل نموذج ممكن لتصنيف البيانات. ابدأ أولا بقراءة توثيق هذا الأمر:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    " 'C':[0.0001, 0.001, 0.01 , 0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 10., 100.],\n",
    " 'fit_intercept': [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# عليك تعديل هذه الخانة قبل تسليم المشروع\n",
    "# YOU HAVE TO EDIT THIS CELLL\n",
    "############################\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gsearch1 = # YOUR CODE HERE\n",
    "\n",
    "\n",
    "gsearch1.fit(train_data,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "بعد أن أنجزنا عملية البحث، سنقوم بطباعة أفضل \"تشكيلة\" من المدخلات والتي تملك أعلى درجة:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "وهنا سنقوم بطباعة أفضل درجة توصل لها البحث باستخدام التشكيلة أعلاه:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "عملية البحث عن نموذج عملية قد تأخذ وقتاً طويلاً جداً. فأعلاه، لدينا 22 نموذج مختلف (١١ ضرب ٢)، كل نموذچ يمر عبر التحقق المتقاطع ذو 5 أقسام بما معناه أننا نقوم بمطابقة النموذج 110 مرات! وهنا يأتي دور الإمكانيات المتقدمة في تسريع هذه العملية. بشكل عام، لا غنى عن أداء هذا البحث في أي نموذج معقد يتطلب العديد من المدخلات. لنكرر نفس الأمر أدناه ولكن مع نموذج الغابات العشوائية"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# عليك تعديل هذه الخانة قبل تسليم المشروع\n",
    "# YOU HAVE TO EDIT THIS CELLL\n",
    "############################\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    " 'min_samples_split':[2,3,5],\n",
    " 'min_samples_leaf':[2,3,5],\n",
    " 'max_features': ['auto', 'log2', 'sqrt']\n",
    "}\n",
    "\n",
    "gsearch2 = # YOUR CODE HERE\n",
    "\n",
    "\n",
    "gsearch2.fit(train_data,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "بعد أن أنجزنا عملية البحث، سنقوم بطباعة أفضل \"تشكيلة\" من المدخلات والتي تملك أعلى درجة:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "وهنا سنقوم بطباعة أفضل درجة توصل لها البحث باستخدام التشكيلة أعلاه:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "\n",
    "# تسليم المشروع"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "قبل تسليم المشروع في موقع كاقل، سوف نستخدم النموذج الأفضل من النماذج أعلاه لمطابقته على جميع البيانات."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(**gsearch1.best_params_) # نلاحظ هنا طريقة استخدام المدخلات"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data, y) # training model on full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('predict-who-is-more-influential-in-a-social-network/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = get_process_features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame(scaler.transform(test_data.values), columns=test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Choice'] = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.index.name = 'Id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.index = test_data.index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Choice'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Choice'].to_csv('./social_media_analysis_submission.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "والآن اذهب إلى موقع كاقل وقم برفع هذا الملف لترى قوة النموذج:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.kaggle.com/c/predict-who-is-more-influential-in-a-social-network/submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "تسليم هذا المشروع على مرحلتين: الأولى هي في تسليم الملف إلى موقع كاقل ومن ثم مشاركة الرابط، والمرحلة الثانية هي باستكمال الخانات التي تحتاج إلى إكمال ومن ثم التأكد من سلامتها."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
